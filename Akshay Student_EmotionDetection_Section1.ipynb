{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HLEd_u-TwoaGUtMeE1w3HFsJKSjz128F","timestamp":1690734792205}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TiM6gYg0nhkY"},"source":["<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"]},{"cell_type":"code","metadata":{"id":"vTvlQpRbknCZ","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690737936804,"user_tz":300,"elapsed":679,"user":{"displayName":"Akshay Maram","userId":"16512910310724031389"}},"outputId":"a3526dfe-1558-4bf2-ef71-c704ded66642"},"source":["#@title Run this to prepare our environment\n","\n","\n","# Imports the required libraries\n","import cv2\n","import dlib\n","import math\n","import unittest\n","import numpy as np\n","import urllib.request\n","\n","from scipy.spatial import distance\n","from matplotlib import pyplot as plt\n","\n","###Getting the Dlib Shape predictor!\n","!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat\"\n","dlibshape_path ='./shape_predictor_68_face_landmarks.dat'\n","\n","print (\"Done\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shape_predictor_68_ 100%[===================>]  95.08M   216MB/s    in 0.4s    \n","Done\n"]}]},{"cell_type":"code","metadata":{"id":"UVv-vnL2AyPc","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690737949566,"user_tz":300,"elapsed":12763,"user":{"displayName":"Akshay Maram","userId":"16512910310724031389"}},"outputId":"bd54e26f-7860-466b-9d07-7aca622ac19a"},"source":["#@title If the previous code cell fails to download the data properly, please run this.\n","import cv2\n","import dlib\n","import pickle\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import urllib.request\n","from sklearn import metrics\n","from scipy.spatial import distance\n","from matplotlib import pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","import io\n","# ?pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n","# warnings.filterwarnings(\"ignore\")\n","\n","%pip install googledrivedownloader\n","# from google_drive_downloader import GoogleDriveDownloader as gdd\n","# gdd.download_file_from_google_drive(file_id='1hNLedQCRl8uutOwtXWxBmiW3x7bckj4u',\n","#                                     dest_path='./ferdata.csv', overwrite=True,showsize=True)\n","#Getting the csv data loaded\n","!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/fer2013_5.csv'\n","\n","###Getting the Dlib Shape predictor!\n","!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat'\n","\n","###Getting the Xpure loaded\n","!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/pureX.npy'\n","\n","###Getting the Xdata loaded\n","!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataX.npy'\n","\n","###Getting the Ydata loaded\n","!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataY.npy'\n","\n","print (\"Data Downloaded!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (0.4)\n","fer2013_5.csv.3     100%[===================>] 159.97M   183MB/s    in 0.9s    \n","shape_predictor_68_ 100%[===================>]  95.08M   159MB/s    in 0.6s    \n","pureX.npy.3         100%[===================>]  43.95M   181MB/s    in 0.2s    \n","dataX.npy.3         100%[===================>] 695.19M   187MB/s    in 5.9s    \n","dataY.npy.3         100%[===================>] 156.38K  --.-KB/s    in 0.001s  \n","Data Downloaded!\n"]}]},{"cell_type":"markdown","metadata":{"id":"XdMUXYoMKQnt"},"source":["# Emotion Detection\n","\n","Have you ever been in a situation where you signed up for an online course, however, after attending couple of sessions, you dropped out of the course?\n","According to facts, more than 70 % people enrolled in online courses tend to dropout. Why is it so? Well, there could be multiple reasons to this such as the unadaptable teaching style, quality and the difficulty of the teaching content, etc.\n","\n","However, if a feedback system which could predict the emotion of the student as to if they were delighted, frustrated or confused was incorporated, wouldn't it make learning better?\n","\n","Well, of course it would! Imagine a scenario where confusion was seen as prominent emotion within the class. What it could possibly imply is that students either didn't understand the content or couldn't adhere to tutor's teaching style. This kind of feedback can be taken into account so that the upcoming sessions could be suited better to the needs of the students.\n","\n","Emotion Detection has a wide variety of applications. Smart cars with facial emotion detection technology can help understand if the driver is feeling drowsy and send driver personalized alerts to stop for a coffee break or change the music, etc.\n","\n","Companies are also using emotion detection during the Video Game Testing phase. It helps them understand which emotions are experienced at what points in the game. Taking written feedback from the user who has experienced the game can be inefficient. This is because it can often be difficult to put an experience into words.\n","\n","Facial Emotion detection is a practical means of going beyond the spoken or written feedback and appreciating what the user is experiencing. Such is more reliable than other forms of feedback.\n","\n","![Demo](https://media.gettyimages.com/photos/facial-recognition-of-caucasian-businessman-picture-id905553688?k=6&m=905553688&s=612x612&w=0&h=05pKk6IgZ8SGLOGWdKIkcVz4toQEThSV40TguY5xAh8=)"]},{"cell_type":"markdown","metadata":{"id":"ltAe5xuBUl6M"},"source":["You and your group are going to build an AI tool that can help predict the emotions based on the Facial Expressions.\n","\n","You will classify the facial expressions into one of the following core emotions: **Anger, Happy, Sad, Surprise, and Neutral**."]},{"cell_type":"markdown","metadata":{"id":"EIrowe2Atd1W"},"source":["In this notebook we'll be:\n","1.   Understanding Face Detection\n","2.   Understanding Facial Landmarks\n","2.   Understanding Euclidean Distances\n","2.   Understanding Emotion Detection\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RfScS6ztabOs"},"source":["## Exercise 1 (5 Minutes) | Discussion: How should we set up this problem\n","\n","- What \"features\" might be useful in recognizing emotion?\n","- What steps would you take to identify and use these features for emotion recognition?\n","- How would you set up this problem using the tools we've learned in this course?\n","- What are some applications for this machine learning approach to emotion recognition?\n","- What might be missing from this approach?"]},{"cell_type":"markdown","metadata":{"id":"_u8_a0JelHpd"},"source":["#Milestone 1: Understanding Face Detection"]},{"cell_type":"markdown","metadata":{"id":"k6i534TRm98_"},"source":["**What is Face Detection?**\n","\n","Face detection is a computer vision technology that helps to locate human faces in images. This technique is a specific use case of object detection technology that deals with detecting instances of semantic objects of a certain class (such as humans, buildings or cars) in images and videos."]},{"cell_type":"markdown","metadata":{"id":"jQzflPFunFSr"},"source":["\n","\n","![alt text](https://cdn.xl.thumbs.canstockphoto.com/happy-woman-with-umbrella-walking-in-autumn-park-season-weather-and-people-concept-beautiful-stock-photo_csp40883320.jpg)"]},{"cell_type":"markdown","metadata":{"id":"RU3qbfPbnFPR"},"source":["## Exercise 2 (Discussion) | 5 minutes\n","\n","- What emotion is depicted in the image above?\n","- Which part of the image helped you predict the emotion?\n","- What steps did you take to recognize this emotion?\n","\n","You can visit [this site](https://imotions.com/blog/facial-action-coding-system) to look at how human facial expressions have been segmented into groups."]},{"cell_type":"markdown","metadata":{"id":"H_rNLO05tEWA"},"source":["##Face Detection Demonstration\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iB26IT8utRwi"},"source":["Face detection is an important step in the emotion classification pipeline. It helps us eliminate parts of the image which have no relevance in detecting the emotion."]},{"cell_type":"markdown","metadata":{"id":"6KR5meZxv-nq"},"source":["Face detection algorithms are used to predict the bounding box coordinates of the face.\n","\n","\n","\n","![](https://drive.google.com/uc?id=1oxMqFcBJgk-Z1DAc82a8XZESslzaxoA0)\n","<!-- https://www.researchgate.net/figure/Different-types-of-face-bounding-boxes-boxes-detected-by-Viola-Jones-detector-boxes_fig2_338168587 -->\n","\n","Dlib is a popular Python library complied in C++. For this project we will use\n","Dlib's pre-trained face detection model to extract the bounding box coordinates of the face.\n"]},{"cell_type":"markdown","metadata":{"id":"OKcl354K4cAF"},"source":["###Load Pretrained Dlib model"]},{"cell_type":"code","metadata":{"id":"2-pHGj2OkRWJ"},"source":["# Load's dlib's pretrained face detector model\n","frontalface_detector = dlib.get_frontal_face_detector()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQnR1UJVmW2r","cellView":"form"},"source":["#@title Run this cell to define a helper function for face detection\n","\n","'''\n","  Converts dlib rectangular object to bounding box coordinates\n","'''\n","def rect_to_bb(rect):\n","    # take a bounding predicted by dlib and convert it\n","    # to the format (x, y, w, h) as we would normally do\n","    # with OpenCV\n","    x = rect.left()\n","    y = rect.top()\n","    w = rect.right() - x\n","    h = rect.bottom() - y\n","    return (x, y, w, h)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vo7m32hHnE7u","cellView":"form"},"source":["#@title Run this cell to define a helper function for face detection with a given image\n","\n","\"\"\"\n","Detects the face in the given image\n","\"\"\"\n","def detect_face(image_url):\n","  \"\"\"\n","  :type image_url: str\n","  :rtype: None\n","\n","  \"\"\"\n","  try:\n","\n","    #Decodes image address to cv2 object\n","    url_response = urllib.request.urlopen(image_url)\n","    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n","    image = cv2.imdecode(img_array, -1)\n","\n","  except Exception as e:\n","    return \"Please check the URL and try again!\"\n","\n","  #Detect faces using dlib model\n","  rects = frontalface_detector(image, 1)\n","\n","  if len(rects) < 1:\n","    return \"No Face Detected\"\n","\n","  # Loop over the face detections\n","  for (i, rect) in enumerate(rects):\n","    # Converts dlib rectangular object to bounding box coordinates\n","    (x, y, w, h) = rect_to_bb(rect)\n","    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","  plt.imshow(image, interpolation='nearest')\n","  plt.axis('off')\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llTv-nv44YX4"},"source":["### Face Detection"]},{"cell_type":"markdown","metadata":{"id":"Erulyghe4T_a"},"source":["###Try it Out!!!"]},{"cell_type":"code","metadata":{"id":"1g5S3o_euWsQ"},"source":["# https://www.clickinmoms.com/blog/wp-content/uploads/2014/10/black-and-white-portrait-of-man-with-his-eyes-closed-by-Brian-Powers.jpg\n","# https://i.pinimg.com/736x/a8/59/05/a85905aad4b379aafd63bbbd3144025d--freya-mavor-beautiful-people.jpg\n","# https://i.pinimg.com/236x/27/28/0e/27280ee28567c1e20c119f74981ee5c4--black-freckles-freckles-makeup.jpg\n","\n","# Give the path of the image for face detection\n","detect_face(input('Enter the URL of the image: '));  # run cell and when prompted, input a URL of an img and press 'enter'!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cD34pERNy6my"},"source":["#Milestone 2: Understanding Facial Landmarks"]},{"cell_type":"markdown","metadata":{"id":"_uaTewLrzINj"},"source":["**What are Facial Landmarks?**\n","\n","\n","Facial landmarks are a set of key points on human face images. They represent the points of interest within the face. The points are defined by their (x,y) coordinates on the image, and are used to locate and represent salient regions of the face, such as eyes, eyebrows, nose, mouth and jawline."]},{"cell_type":"markdown","metadata":{"id":"4V4NJXsN0jXS"},"source":["##Facial Landmark Demonstration"]},{"cell_type":"markdown","metadata":{"id":"520Q_tTT0Zbh"},"source":["Facial landmark estimation is an important feature extraction step in solving a variety of applications such as face recognition, facial expression recognition, face swapping, face filters and much more."]},{"cell_type":"markdown","metadata":{"id":"QqTlwL4uYPrD"},"source":["The number of facial key points on the face can be variable depending on the pre-trained facial landmark model being used.<br>\n","\n","\n","\n","\n","<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ3TMlMcOORwi88JUPO3xvHbjl8yBGDZnMMNhfpY5pS4Mvq_n7w' width='550' ><br>\n","For this project, we will be using Dlib's pretrained Facial Landmark Detection Model which will help us detect 68 2-Dimensional points on the human face.\n","\n","<br> The image above shows the location and indices of the 68 facial landmarks.\n"]},{"cell_type":"markdown","metadata":{"id":"qZteCP8pz7KL"},"source":["## Facial Landmark Estimation using DLib\n","\n","In this section, we are going to look at the code to extract and plot the 68 facial landmarks for the given image.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CB9fqreHQJtk"},"source":["###Load Pre-trained DLib models"]},{"cell_type":"code","metadata":{"id":"KhVSMc7I1sX_"},"source":["# Load's dlib's pretrained face detector model\n","frontalface_detector = dlib.get_frontal_face_detector()\n","#Load the 68 face Landmark file\n","landmark_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAI9BJyoPoyl"},"source":["### Extracting Facial Landmarks"]},{"cell_type":"code","metadata":{"id":"HdV7TDoz14QL","executionInfo":{"status":"ok","timestamp":1691352677454,"user_tz":300,"elapsed":150,"user":{"displayName":"Akshay Maram","userId":"16512910310724031389"}}},"source":["#@title Run this cell to define a helper function for face detection from a url\n","\n","\n","\"\"\"\n","Returns facial landmarks for the given input image path\n","\"\"\"\n","def get_landmarks(image_url):\n","  \"\"\"\n","  :type image_url : str\n","  :rtype image : cv2 object\n","  :rtype landmarks : list of tuples where each tuple represents\n","                     the x and y coordinates of facial keypoints\n","  \"\"\"\n","\n","  try:\n","\n","    #Decodes image address to cv2 object\n","    url_response = urllib.request.urlopen(image_url)\n","    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n","    image = cv2.imdecode(img_array, -1)\n","\n","  except Exception as e:\n","    print (\"Please check the URL and try again!\")\n","    return None,None\n","\n","  #Detect the Faces within the image\n","  faces = frontalface_detector(image, 1)\n","  if len(faces):\n","    landmarks = [(p.x, p.y) for p in landmark_predictor(image, faces[0]).parts()]\n","  else:\n","    return None,None\n","\n","  return image,landmarks"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InE6rfBXPkEU"},"source":["###Visualizing Facial Landmarks"]},{"cell_type":"code","metadata":{"id":"l4npmNu0zgKz"},"source":["#@title Run this cell to define a helper function to visualize landmarks\n","\n","\"\"\"\n","Display image with its Facial Landmarks\n","\"\"\"\n","def plot_image_landmarks(image,face_landmarks):\n","  \"\"\"\n","  :type image_path : str\n","  :type face_landmarks : list of tuples where each tuple represents\n","                     the x and y coordinates of facial keypoints\n","  :rtype : None\n","  \"\"\"\n","  radius = -1\n","  circle_thickness = 5\n","  image_copy = image.copy()\n","  for (x, y) in face_landmarks:\n","    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n","\n","  plt.imshow(image_copy, interpolation='nearest')\n","  plt.axis('off')\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Vl6hSG4P6RJ"},"source":["###Try it Out!!!!"]},{"cell_type":"code","metadata":{"id":"YLeqLY0Xzk1D"},"source":["#Extract the Facial Landmark coordinates\n","image,landmarks= get_landmarks(input(\"Enter the URL of the image: \")) #url\n","\n","#Plot the Facial Landmarks on the face\n","if landmarks:\n","  plot_image_landmarks(image,landmarks)\n","else:\n","  print (\"No Landmarks Detected\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFKqtolfgouD","cellView":"form"},"source":["#@title Run (and eventually edit) this cell to visualize the features we've extracted\n","\n","def show_indices(landmarks, i_index):\n","\n","  plt.scatter(x=[landmarks[i][0] for i in range(len(landmarks)//2, len(landmarks))],\n","              y=[-landmarks[i][1] for i in range(len(landmarks)//2, len(landmarks))], s=50, alpha=.5, color='blue', label='second half of indices')\n","\n","  plt.scatter(x=[landmarks[i][0] for i in range(len(landmarks)//2)],\n","              y=[-landmarks[i][1] for i in range(len(landmarks)//2)], color='red', alpha=.5, label='first half of indices')\n","\n","  # what should X and Y be to visualize the feature at i_index?\n","  x = landmarks[i_index][0]\n","  y = -landmarks[i_index][1]\n","  plt.scatter(x=x, y=y,\n","             color='purple', s=100, marker='x', label='feature at index %d'%i_index)\n","\n","  plt.scatter(x, y, color='red', alpha=.5, label='selected indices')\n","\n","  plt.axis('off');\n","  plt.legend(bbox_to_anchor=[1,1]);\n","  plt.title('Visualizing the features we\\'ve extracted from this image',y =1.2);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FX7o0LZgp6e"},"source":["show_index = 28\n","show_indices(landmarks, show_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vI6NGcpsSjoC"},"source":["np.array(landmarks).shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nanct0VrFr5S"},"source":["## Exercise 2B (Discussion) | 10 Minutes | Within a student group\n","\n"]},{"cell_type":"code","metadata":{"id":"DUjwuDg6JjRq"},"source":["#@title Which facial landmark points correspond to which part of the face? { display-mode: \"form\" }\n","LeftEye= \"36-41\" #@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","RightEye = \"42-47\"#@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","Eyebrows = \"17-26\"#@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","Nose = \"27-35\"#@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","Mouth = \"48-67\"#@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","Jawline = \"0-16\"#@param[\"0-16\", \"17-26\", \"27-35\",\"36-41\",\"42-47\",\"48-67\",\"Fill Me In\"]\n","\n","\n","\n","\n","if LeftEye == \"36-41\":\n","  print(\"The Left eye can be accessed through points %s\"%LeftEye)\n","else:\n","  print('Not quite %s'%LeftEye)\n","\n","if RightEye == \"42-47\":\n","  print(\"The Right eye can be accessed through points %s\"%RightEye)\n","else:\n","  print('Not quite %s'%RightEye)\n","\n","if Eyebrows == \"17-26\":\n","  print(\"The Eyebrows can be accessed through points %s\"%Eyebrows)\n","else:\n","  print('Not quite %s'%Eyebrows)\n","\n","if Nose == \"27-35\":\n","  print(\"The Nose can be accessed through points %s\"%Nose)\n","else:\n","  print('Not quite %s'%Nose)\n","\n","if Mouth == \"48-67\":\n","  print(\"The Mouth can be accessed through points %s\"%Mouth)\n","else:\n","  print('Not quite %s'%Mouth)\n","\n","if Jawline == \"0-16\":\n","  print(\"The Jawline can be accessed through points %s\"%Jawline)\n","else:\n","  print('Not quite %s'%Jawline)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZBtFtUkN4RF"},"source":["## Exercise 2C (Coding)\n","\n","In this section, you will modify the inputs to `plot_image_landmarks`  function defined in previous section to detect and display different parts of the face individually using facial landmarks.\n","\n","Write code to detect eyes, nose, mouth, jawline and eyebrows using facial landmarks.\n","\n","Hint: To detect the eyes, you need to plot facial landmark points from 36-47\n","\n","Note: Make sure you have valid facial landmark output after running the previous block (Try it Out Section!)"]},{"cell_type":"code","metadata":{"id":"kX7f7xrq_e9j"},"source":["landmark_indices = {'eyes':(36,47),\n","                    \"nose\":(27,35),\n","                    \"mouth\":(48,67),\n","                    \"jawline\":(0,17),\n","                    \"eyebrow\":(18,27)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDvFceG3N17i"},"source":["# Display images with individual detection of face parts\n","\n","# For example, for eye detection:\n","\n","eye_points = np.array([27,35])\n","selected_landmarks = landmarks[eye_points[0]:eye_points[1]+1]\n","print(selected_landmarks)\n","plot_image_landmarks(image,selected_landmarks)\n","\n","### YOUR CODE HERE\n","\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A355Uv7wDMDl"},"source":["#Milestone 3: Understanding Euclidean Distances\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hbf8TZPw-A7r"},"source":["Euclidean distance is the length of the line segment connecting two points. When data is dense or continuous, this is the best proximity measure.\n","\n","The equation is as follows. Given two points $p$ and $q$:\n","$$distance(p, q) = \\sqrt{(q_x-p_x)^2+(q_y-p_y)^2}$$\n","\n","In this section, we will explore how euclidean distance between pairs of facial landmarks can help solve simple use cases related to faces."]},{"cell_type":"markdown","metadata":{"id":"10B9RCvzC6y7"},"source":["##Exercise 3A (Discussion) | 5 Minutes | Within a student group"]},{"cell_type":"markdown","metadata":{"id":"KtogEi-XkmVP"},"source":["###What is the difference between two images? Can you use facial landmarks  to distinguish between the two images?"]},{"cell_type":"markdown","metadata":{"id":"AgWCy3ho-s2U"},"source":["Take a look at the images with facial landmarks superimposed over them!\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GNTeQplZOarM"},"source":["![alt-text](data:image/jpeg;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"_XQvxhwvSnYR"},"source":["Does the distance between certain facial landmarks help us distinguish between two images?"]},{"cell_type":"markdown","metadata":{"id":"g4awukiot2tu"},"source":["##Exercise 3B (Coding) | Are the eyes open or closed?\n","\n","In the last block, we figured out which set of landmarks help us distinguish between the two images. In this section, you will write code to distinguish between closed eyes and open eyes using facial landmarks.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cmSPfiVZ-_7a"},"source":["###Euclidean Distance\n","\n","Write a function to compute the euclidean distance between two points:"]},{"cell_type":"code","metadata":{"id":"u_IsP9gUpcun"},"source":["\"\"\"\n","Computes the euclidean distance between 2 points p and q in 2D space\n","#inexing#math.sqrt\n","\"\"\"\n","def euclidean_distance(p,q):\n","  \"\"\"\n","  type p, q : tuple\n","  rtype distance: float\n","  \"\"\"\n","  ### YOUR CODE HERE\n","  distance = math.sqrt(((q[0]-p[0])**2) + ((q[1]-p[1])**2))\n","  return distance\n","  ### END CODE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's test to see if your distance function works! According to the [3-4-5 triangle rule](https://www.mathsisfun.com/geometry/triangle-3-4-5.html) in math, the distance between points (0,0) and (3,4) should be 5!"],"metadata":{"id":"8oBAvNbqVZ9P"}},{"cell_type":"code","source":["p = (0, 0) # Your first point, p\n","q = (3, 4) # Your second point, q\n","print(\"The distance between points \",p,\" and \",q,\" is: \",euclidean_distance(p, q))"],"metadata":{"id":"81aoPYj7U_6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xw2ZuICTir0Q"},"source":["### Are there other distance metrics we can use here?"]},{"cell_type":"markdown","metadata":{"id":"XQZnD_48_Dl8"},"source":["###Classify images based on eyes\n","\n","Write code to find out which image corresponds to closed eyes and which image corresponds to open eyes using the concept of euclidean distance\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_7enTs1C7Jj8"},"source":["###Pseudo-Algorithm\n","\n","1. Identity the facial landmarks of interest\n","2. Compute the distances between the points of interest\n","3. Compare the distances of both the images\n"]},{"cell_type":"code","metadata":{"id":"0tHD4KL10Mn4"},"source":["\"\"\"\n","Distinguishes between two images--->closed eyes v/s open eyes\n","\"\"\"\n","def classify_images(image1_path,image2_path,plt_flag):\n","  \"\"\"\n","  type image1_path,image2_path: str\n","  type plt_flag: boolean #Displays input images if True\n","  rtype : str\n","  \"\"\"\n","  image1,image1_landmarks = get_landmarks(image1_path)\n","  image2,image2_landmarks = get_landmarks(image2_path)\n","\n","  if plt_flag:\n","    #Plot image1\n","    plt.imshow(image1, interpolation='nearest')\n","    plt.title(\"Image1\")\n","    plt.show()\n","\n","    #Plot image2\n","    plt.imshow(image2, interpolation='nearest')\n","    plt.title(\"Image2\")\n","    plt.show()\n","  ### YOUR CODE HERE\n","  pairs_distance = [(37,41),(38,40),(43,47),(44,46)]\n","  sum_1 = 0\n","  sum_2 = 0\n","  for pair in pairs_distance:\n","    sum_1+=euclidean_distance(image1_landmarks[pair[0]],image1_landmarks[pair[1]])\n","    sum_2+=euclidean_distance(image2_landmarks[pair[0]],image2_landmarks[pair[1]])\n","\n","  difference = sum_2-sum_1\n","\n","  ### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCAZ73T2bsPS"},"source":["### Exercise 3C (Discussion) | 5 Minutes | Within a student group"]},{"cell_type":"markdown","metadata":{"id":"fW0G6t-L-R0z"},"source":["###Take a look at the images below! Do you think our logic would work for all the image sets?\n","\n","<div id=\"horizontal\">\n","\n","<img src=\"https://cdn.pixabay.com/photo/2020/02/04/21/31/luck-4819408_1280.jpg\" width=200 height=300></img>\n","\n","<img src=\"https://media-gadventures.global.ssl.fastly.net/media-server/dynamic/blogs/posts/peter-west-carey/2015/05/Peter-West-Carey-India2011-1030-9236.jpg\" width=200 height=300></img>\n","\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"YxZETngJefRU"},"source":["##Optional Activity (Coding)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jHyaqS-Hel-L"},"source":["Modify your code to distinguish between open and closed mouth using facial landmarks."]},{"cell_type":"code","metadata":{"id":"uIq65g8Yez0u"},"source":["### YOUR CODE HERE\n","\n","### END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"csUQshl1fer7"},"source":["#Milestone 4: Understanding Emotion Detection"]},{"cell_type":"markdown","metadata":{"id":"pPUWsQkJr32l"},"source":["##What distinguishes one emotion from another?\n","\n","<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTGK2Z6d7NBBt-cE1OGEAw4fN7KknxBBOGWrQ&usqp=CAU\"></img>\n","\n","<img src=\"https://cdn.pixabay.com/photo/2017/08/25/21/44/shocked-2681488__340.jpg\"></img>"]},{"cell_type":"markdown","metadata":{"id":"Pe0Jf4HGsCoM"},"source":["##Exercise (Discussion) | 10 Minutes | Within a student group"]},{"cell_type":"markdown","metadata":{"id":"FwyOqxKgsHz1"},"source":["\n","\n","*   **What distinguishes Happy Face from Surprised Face?**\n","*   **What distinguishes Happy Face from Neutral Face?**\n","*   **What distinguishes Happy Face from Sad Face?**\n","*   **What distinguishes Happy Face from Angry Face?**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"opCzMUPBFKzq"},"source":["#Finish!"]}]}